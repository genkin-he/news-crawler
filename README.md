# æ–°é—»çˆ¬è™« Cloud Functions + BigQuery

æ–°é—»çˆ¬è™« Google Cloud Functions + BigQuery çš„é¡¹ç›®ã€‚

## é¡¹ç›®ç‰¹ç‚¹

- **æ— æœåŠ¡å™¨æ¶æ„**: ä½¿ç”¨ Cloud Functions æŒ‰éœ€æ‰§è¡Œçˆ¬è™«
- **æ•°æ®æŒä¹…åŒ–**: BigQuery æŒ‰æ—¥æœŸåˆ†åŒºå­˜å‚¨ï¼Œæ”¯æŒ SQL æŸ¥è¯¢
- **é«˜æ•ˆå»é‡**: åŸºäº BigQuery åˆ†åŒºæŸ¥è¯¢çš„å»é‡æœºåˆ¶
- **å¹¶å‘çˆ¬å–**: å¤šä¸ªæ–°é—»æºå¹¶å‘æ‰§è¡Œï¼Œæé«˜æ•ˆç‡
- **å®šæ—¶è§¦å‘**: Cloud Scheduler æ¯ 10 åˆ†é’Ÿè‡ªåŠ¨è§¦å‘
- **è¶…ä½æˆæœ¬**: é¢„è®¡æ¯æœˆä»… **$4-7**

## æŠ€æœ¯æ ˆ

- **è¿è¡Œæ—¶**: Python 3.11
- **è®¡ç®—**: Google Cloud Functions (Gen 2)
- **æ•°æ®åº“**: Google BigQueryï¼ˆæŒ‰æ—¥æœŸåˆ†åŒºï¼‰
- **è°ƒåº¦**: Google Cloud Scheduler
- **ä¾èµ–**: BeautifulSoup4, requests, google-cloud-bigquery

## é¡¹ç›®ç»“æ„

```
news-google/
â”œâ”€â”€ main.py                      # åŒå…¥å£ï¼šcrawl_newsï¼ˆç®€å•ï¼‰+ crawl_news_browserï¼ˆæ— å¤´æµè§ˆå™¨ï¼‰
â”œâ”€â”€ Makefile                     # æœ¬åœ°è¿è¡Œä¸éƒ¨ç½²ï¼ˆmake run / deploy / deploy-browserï¼‰
â”œâ”€â”€ requirements.txt            # ç®€å•çˆ¬è™«ä¾èµ–
â”œâ”€â”€ requirements-browser.txt    # æ— å¤´æµè§ˆå™¨çˆ¬è™«ä¾èµ–ï¼ˆplaywright ç­‰ï¼‰
â”œâ”€â”€ config.yaml                 # é…ç½®æ–‡ä»¶ï¼ˆGCPã€å¹¶å‘ç­‰ï¼‰
â”œâ”€â”€ scrapers/
â”‚   â”œâ”€â”€ base_scraper.py
â”‚   â”œâ”€â”€ simple/                 # ç®€å•çˆ¬è™«ï¼ˆrequests/BeautifulSoupï¼Œæ— æµè§ˆå™¨ï¼‰
â”‚   â”‚   â”œâ”€â”€ techcrunch.py
â”‚   â”‚   â”œâ”€â”€ apnews.py
â”‚   â”‚   â””â”€â”€ coinlive.py
â”‚   â””â”€â”€ browser/                # æ— å¤´æµè§ˆå™¨çˆ¬è™«ï¼ˆPlaywrightï¼Œä»… crawl_news_browser ä½¿ç”¨ï¼‰
â”‚       â”œâ”€â”€ base_browser_scraper.py
â”‚       â”œâ”€â”€ stcn.py
â”‚       â”œâ”€â”€ koreatimes.py
â”‚       â””â”€â”€ __init__.py         # SCRAPER_REGISTRY_BROWSER
â”œâ”€â”€ utils/
â””â”€â”€ deploy/
    â”œâ”€â”€ deploy.sh               # éƒ¨ç½² crawl-newsï¼ˆç®€å•ï¼‰â†’ Cloud Functions
    â”œâ”€â”€ deploy_cloudrun_browser.sh  # æ— å¤´æµè§ˆå™¨çˆ¬è™« â†’ Cloud Runï¼ˆå« Scheduler å®šæ—¶è§¦å‘ï¼‰
    â”œâ”€â”€ setup_scheduler.sh       # å®šæ—¶è§¦å‘ crawl-news
    â””â”€â”€ create_bigquery_table.sql
â””â”€â”€ Dockerfile.firefox          # Cloud Run æ— å¤´æµè§ˆå™¨é•œåƒï¼ˆä»… Firefoxï¼Œä½“ç§¯å°ï¼‰
```

**ä¸¤ä¸ªå…¥å£ï¼ˆä¾èµ–éš”ç¦»ï¼‰**

| åç§° | å…¥å£ | ä¾èµ– | éƒ¨ç½²æ–¹å¼ |
|------|------|------|----------|
| ç®€å•çˆ¬è™« | `crawl_news` | requirements.txt | Cloud Functionsï¼ˆ`deploy.sh`ï¼‰ |
| æ— å¤´æµè§ˆå™¨çˆ¬è™« | `crawl_news_browser` | requirements-browser.txt + **æµè§ˆå™¨äºŒè¿›åˆ¶** | **Cloud Run**ï¼ˆ`deploy_cloudrun_browser.sh`ï¼‰ |

**é‡è¦**ï¼šæ— å¤´æµè§ˆå™¨çˆ¬è™«ä¾èµ– Playwright çš„**æµè§ˆå™¨äºŒè¿›åˆ¶**ï¼Œéœ€ç”¨ **Cloud Run + Dockerfile.firefox**ï¼ˆä»…å« Firefoxï¼Œä½“ç§¯å°ï¼‰éƒ¨ç½²ã€‚

## å¿«é€Ÿå¼€å§‹

### 1. å‰ç½®å‡†å¤‡

1. **å®‰è£… Google Cloud SDK**
   ```bash
   # macOS
   brew install --cask google-cloud-sdk

   # ç™»å½•
   gcloud auth login
   gcloud auth application-default login
   ```

2. **è®¾ç½®ç¯å¢ƒå˜é‡**
   ```bash
   export GCP_PROJECT_ID="your-project-id"
   export GCP_REGION="us-central1"
   ```

3. **ä¿®æ”¹é…ç½®æ–‡ä»¶**
   ç¼–è¾‘ `config.yaml`ï¼Œæ›¿æ¢ `your-project-id` ä¸ºæ‚¨çš„ GCP é¡¹ç›® ID

### 2. åˆ›å»º GCP èµ„æº

1. **åˆ›å»º BigQuery æ•°æ®é›†å’Œè¡¨**
   ```bash
   bq query --use_legacy_sql=false < deploy/create_bigquery_table.sql
   ```

### 3. éƒ¨ç½²

**ä½¿ç”¨ Makefileï¼ˆæ¨èï¼‰**
```bash
export GCP_PROJECT_ID="your-project-id"
make deploy              # éƒ¨ç½²ç®€å•çˆ¬è™«åˆ° Cloud Functions
make deploy-browser      # éƒ¨ç½²æ— å¤´æµè§ˆå™¨çˆ¬è™«åˆ° Cloud Run + Scheduler
make deploy-all         # ä¾æ¬¡æ‰§è¡Œä¸Šè¿°ä¸¤è€…
```

**æˆ–ç›´æ¥æ‰§è¡Œè„šæœ¬**
```bash
cd /path/to/news-google
sh deploy/deploy.sh                    # ç®€å•çˆ¬è™« â†’ Cloud Functions
sh deploy/deploy_cloudrun_browser.sh  # æ— å¤´æµè§ˆå™¨ â†’ Cloud Runï¼ˆå«æ¯ 30 åˆ†é’Ÿå®šæ—¶è§¦å‘ï¼‰
```

**é…ç½®å®šæ—¶ä»»åŠ¡ï¼ˆå¯é€‰ï¼‰**
- ç®€å•çˆ¬è™«æ¯ 10 åˆ†é’Ÿï¼š`./deploy/setup_scheduler.sh`
- æ— å¤´æµè§ˆå™¨çˆ¬è™«ï¼š`deploy_cloudrun_browser.sh` éƒ¨ç½²å®Œæˆåä¼šè‡ªåŠ¨é…ç½®æ¯ 30 åˆ†é’Ÿè§¦å‘

### 4. æµ‹è¯•

**æ‰‹åŠ¨è§¦å‘æµ‹è¯•**
```bash
# æµ‹è¯•å•ä¸ªæ–°é—»æº
curl -X POST -H "Content-Type: application/json" \
  -d '{"sources": "techcrunch"}' \
  https://REGION-PROJECT.cloudfunctions.net/crawl-news

# æµ‹è¯•æ‰€æœ‰æ–°é—»æº
curl -X POST -H "Content-Type: application/json" \
  -d '{"sources": "all"}' \
  https://REGION-PROJECT.cloudfunctions.net/crawl-news
```

**æœ¬åœ°æµ‹è¯•**

éœ€åœ¨é¡¹ç›®æ ¹ç›®å½•æ‰§è¡Œï¼Œå¹¶å·²é…ç½® GCP è®¤è¯ï¼ˆ`gcloud auth application-default login`ï¼‰ã€‚é»˜è®¤ä½¿ç”¨ **uv**ï¼Œä¹Ÿå¯ç”¨ `make run PYTHON=python`ã€‚

**ç®€å•çˆ¬è™«**ï¼ˆtechcrunch / apnews / coinliveï¼‰
```bash
make run
# æˆ–
uv run python main.py
# æˆ–
pip install -r requirements.txt && python main.py
```

**æ— å¤´æµè§ˆå™¨çˆ¬è™«**ï¼ˆstcn / koreatimesï¼Œéœ€ Playwright + Firefoxï¼‰
```bash
make install-browser   # é¦–æ¬¡ï¼šå®‰è£… requirements-browser.txt + playwright install firefox
make run-browser       # è¿è¡Œï¼ˆsources=all, test=Trueï¼Œä¸å†™ BigQueryï¼‰
# æˆ–
uv run python main.py browser
```

- `make run`ï¼šç®€å•çˆ¬è™«ï¼Œä¼šè¯·æ±‚ BigQueryï¼ˆé test æ—¶å†™å…¥ï¼‰ã€‚
- `make run-browser`ï¼šæ— å¤´æµè§ˆå™¨çˆ¬è™«ï¼›æœ¬åœ°é»˜è®¤ `test=True` ä¸å†™ BigQueryã€‚

### 5. æŸ¥çœ‹æ•°æ®

**æŸ¥è¯¢ BigQuery æ•°æ®**ï¼ˆè¡¨ä¸ºåˆ†åŒºè¡¨ï¼ŒæŸ¥è¯¢éœ€å¸¦ `pub_date` æ¡ä»¶ï¼‰
```sql
-- æœ€è¿‘çˆ¬å–çš„æ–‡ç« ï¼ˆæ›¿æ¢ä¸ºä½ çš„ project.datasetï¼‰
SELECT title, link, source, pub_date, crawled_at
FROM `ä½ çš„é¡¹ç›®ID.news_project.news_articles`
WHERE DATE(pub_date) >= DATE_SUB(CURRENT_DATE(), INTERVAL 7 DAY)
ORDER BY crawled_at DESC
LIMIT 20;

-- å„æ¥æºç»Ÿè®¡
SELECT source, COUNT(*) AS cnt
FROM `ä½ çš„é¡¹ç›®ID.news_project.news_articles`
WHERE DATE(pub_date) >= DATE_SUB(CURRENT_DATE(), INTERVAL 7 DAY)
GROUP BY source
ORDER BY cnt DESC;

-- æŸ¥è¯¢ç‰¹å®šæ–°é—»æº
SELECT title, link, pub_date
FROM `ä½ çš„é¡¹ç›®ID.news_project.news_articles`
WHERE source = 'techcrunch'
  AND DATE(pub_date) >= DATE_SUB(CURRENT_DATE(), INTERVAL 365 DAY)
ORDER BY pub_date DESC
LIMIT 20;
```

**æŸ¥çœ‹ Cloud Functions æ—¥å¿—**
```bash
gcloud logging read \
  "resource.type=cloud_function AND resource.labels.function_name=crawl-news" \
  --limit=50 --format=json
```

## æ”¯æŒçš„æ–°é—»æº

**ç®€å•çˆ¬è™«**ï¼ˆCloud Functionsï¼Œ`crawl_news`ï¼‰
- âœ… techcrunch - TechCrunch ç§‘æŠ€æ–°é—»
- âœ… apnews - AP News è´¢ç»å¸‚åœº
- âœ… coinlive - CoinLive åŠ å¯†è´§å¸æ–°é—»

**æ— å¤´æµè§ˆå™¨çˆ¬è™«**ï¼ˆCloud Runï¼Œ`crawl_news_browser`ï¼‰
- âœ… stcn - è¯åˆ¸æ—¶æŠ¥å¿«è®¯
- âœ… koreatimes - Korea Times åŠ å¯†è´§å¸é¢‘é“

**å›¾ä¾‹**: âœ… å·²å®ç°

## å¼€å‘æŒ‡å—

### æ·»åŠ æ–°çˆ¬è™«

- **ç®€å•çˆ¬è™«**ï¼ˆrequests/BeautifulSoupï¼‰ï¼šåœ¨ `scrapers/simple/` ä¸‹æ–°å»ºæ¨¡å—ï¼Œç»§æ‰¿ `BaseScraper`ï¼Œåœ¨ `main.py` çš„ `SCRAPER_REGISTRY` ä¸­æ³¨å†Œã€‚
- **æ— å¤´æµè§ˆå™¨çˆ¬è™«**ï¼ˆPlaywrightï¼‰ï¼šåœ¨ `scrapers/browser/` ä¸‹æ–°å»ºæ¨¡å—ï¼Œç»§æ‰¿ `BaseBrowserScraper` å¹¶å®ç° `_run_impl()`ï¼Œåœ¨ `scrapers/browser/__init__.py` çš„ `SCRAPER_REGISTRY_BROWSER` ä¸­æ³¨å†Œã€‚

**ç®€å•çˆ¬è™«ç¤ºä¾‹**ï¼ˆ`scrapers/simple/example.py`ï¼‰:
```python
from scrapers.base_scraper import BaseScraper

class ExampleScraper(BaseScraper):
    def __init__(self, bq_client):
        super().__init__('example', bq_client)

    def run(self):
        new_articles = []
        # ... çˆ¬å–æ•°æ®ï¼Œç”¨ self.is_link_exists(link) å»é‡ ...
        if new_articles:
            self.save_articles(new_articles)
        return self.get_stats()
```

åœ¨ `main.py` ä¸­æ³¨å†Œ:
```python
from scrapers.simple.example import ExampleScraper
SCRAPER_REGISTRY = { ..., 'example': ExampleScraper }
```

### è¿ç§»ç°æœ‰çˆ¬è™«

å‚è€ƒ `/Users/genkin/coding/gocode/news/news/scripts/` ä¸­çš„ç°æœ‰çˆ¬è™«ä»£ç ï¼š

1. å¤åˆ¶æ ¸å¿ƒçˆ¬å–é€»è¾‘ï¼ˆ`run()` å’Œ `get_detail()` å‡½æ•°ï¼‰
2. æ›¿æ¢ `util.history_posts()` ä¸º `self.is_link_exists()`
3. æ›¿æ¢ `util.write_json_to_file()` ä¸º `self.save_articles()`
4. ä¿æŒ headers å’Œ URL ä¸å˜

## æˆæœ¬ä¼°ç®— ğŸ’°

- **Cloud Functions**: ~$3-5/æœˆï¼ˆæ¯10åˆ†é’Ÿè§¦å‘ï¼Œ512MBå†…å­˜ï¼‰
- **BigQuery**: ~$1-2/æœˆï¼ˆå­˜å‚¨+æŸ¥è¯¢ï¼‰
- **æ€»è®¡**: çº¦ **$4-7/æœˆ** âœ¨

### å»é‡è¯´æ˜

- å¯åŠ¨æ—¶æŒ‰æºæ‹‰å–æœ€æ–° 20 æ¡ URL å…¥å†…å­˜ï¼Œå­˜åœ¨æ€§æ£€æŸ¥èµ°å†…å­˜ï¼Œå‡å°‘ BigQuery æŸ¥è¯¢
- è¡¨æŒ‰ `pub_date` åˆ†åŒºï¼Œéœ€å¸¦åˆ†åŒºæ¡ä»¶çš„æŸ¥è¯¢
- ç®€å•çˆ¬è™«ä¸æ— å¤´æµè§ˆå™¨çˆ¬è™«åˆ†åˆ«éƒ¨ç½²ï¼ˆCloud Functions / Cloud Runï¼‰ï¼Œäº’ä¸å¹²æ‰°

### è¿›ä¸€æ­¥ä¼˜åŒ–å»ºè®®

1. å‡å°‘è§¦å‘é¢‘ç‡: 15åˆ†é’Ÿæˆ–30åˆ†é’Ÿä¸€æ¬¡ï¼ˆé™ä½ Cloud Functions æˆæœ¬ï¼‰
2. ä½¿ç”¨ Cloud Run æ›¿ä»£ Cloud Functionsï¼ˆæŒ‰è¯·æ±‚è®¡è´¹ï¼Œå¯èƒ½æ›´ä¾¿å®œï¼‰
3. è°ƒæ•´ BigQuery åˆ†åŒºè¿‡æœŸæ—¶é—´ï¼ˆé»˜è®¤ 365 å¤©ï¼Œå¯ç¼©çŸ­è‡³ 90 å¤©ï¼‰

## ç›‘æ§ä¸å‘Šè­¦

**æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯**
```bash
# å½“æ—¥å„æºçˆ¬å–æ¡æ•°ï¼ˆè¡¨æŒ‰ pub_date åˆ†åŒºï¼ŒæŸ¥è¯¢éœ€å¸¦åˆ†åŒºæ¡ä»¶ï¼‰
bq query --use_legacy_sql=false \
  "SELECT source, COUNT(*) as count
   FROM \`YOUR_PROJECT_ID.news_project.news_articles\`
   WHERE DATE(pub_date) >= CURRENT_DATE()
   GROUP BY source"
```

**è®¾ç½®å‘Šè­¦**ï¼ˆå¯é€‰ï¼‰
- Cloud Monitoring: ç›‘æ§å‡½æ•°æ‰§è¡Œæ—¶é—´å’Œé”™è¯¯ç‡
- BigQuery: ç›‘æ§æ¯æ—¥æ–°å¢æ•°æ®é‡
- Slack/Email: æ¥æ”¶å¼‚å¸¸å‘Šè­¦

## æ•…éšœæ’æŸ¥

### å»é‡æ€§èƒ½é—®é¢˜
- BigQuery æŸ¥è¯¢å·²æŒ‰æ—¥æœŸåˆ†åŒºä¼˜åŒ–ï¼Œä»…æŸ¥è¯¢æœ€è¿‘ 7 å¤©æ•°æ®
- å¯¹äºæ¯ 10 åˆ†é’Ÿè§¦å‘ä¸€æ¬¡çš„åœºæ™¯ï¼Œå½“å‰æ€§èƒ½å·²è¶³å¤Ÿ

### BigQuery å†™å…¥å¤±è´¥
- æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨: `bq show news_project.news_articles`
- æ£€æŸ¥æœåŠ¡è´¦å·æƒé™
- æŸ¥çœ‹ Cloud Functions æ—¥å¿—

### çˆ¬è™«è¶…æ—¶
- å¢åŠ  Cloud Functions è¶…æ—¶æ—¶é—´: `--timeout=540s`
- å‡å°‘å¹¶å‘çˆ¬è™«æ•°é‡: ä¿®æ”¹ `config.yaml` ä¸­çš„ `max_workers`

## å‚è€ƒèµ„æ–™

- [Google Cloud Functions æ–‡æ¡£](https://cloud.google.com/functions/docs)
- [BigQuery æ–‡æ¡£](https://cloud.google.com/bigquery/docs)
- [Cloud Scheduler æ–‡æ¡£](https://cloud.google.com/scheduler/docs)
- [åŸå§‹é¡¹ç›®](https://github.com/genkin-he/news)

## License

MIT License

## ä½œè€…

ä» [genkin-he/news](https://github.com/genkin-he/news) è¿ç§»è€Œæ¥
