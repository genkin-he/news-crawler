# ğŸš€ æ–°é—»çˆ¬è™«éƒ¨ç½²æŒ‡å—

æœ¬æŒ‡å—è¦†ç›–**ç®€å•çˆ¬è™«**ï¼ˆCloud Functionsï¼‰ä¸**æ— å¤´æµè§ˆå™¨çˆ¬è™«**ï¼ˆCloud Runï¼‰çš„éƒ¨ç½²ä¸éªŒè¯ã€‚

## ğŸ“‹ å‰ç½®å‡†å¤‡

### 1. æ£€æŸ¥ç¯å¢ƒ
```bash
gcloud --version
gcloud auth list

# å¦‚æœªç™»å½•
gcloud auth login
gcloud auth application-default login
```

### 2. è®¾ç½®ç¯å¢ƒå˜é‡
```bash
export GCP_PROJECT_ID="your-project-id"
export GCP_REGION="us-central1"
```

âš ï¸ å°† `your-project-id` æ›¿æ¢ä¸ºå®é™…é¡¹ç›® IDã€‚

---

## ğŸ¯ éƒ¨ç½²æ­¥éª¤

### æ–¹æ³• 1ï¼šä½¿ç”¨ Makefileï¼ˆæ¨èï¼‰

åœ¨**é¡¹ç›®æ ¹ç›®å½•**æ‰§è¡Œï¼š

```bash
# ä»…éƒ¨ç½²ç®€å•çˆ¬è™«ï¼ˆCloud Functionsï¼‰
make deploy

# ä»…éƒ¨ç½²æ— å¤´æµè§ˆå™¨çˆ¬è™«ï¼ˆCloud Run + Schedulerï¼‰
make deploy-browser

# ä¸¤è€…éƒ½éƒ¨ç½²
make deploy-all
```

éœ€å·²è®¾ç½® `GCP_PROJECT_ID`ã€‚

---

### æ–¹æ³• 2ï¼šä¸€é”®éƒ¨ç½²ç®€å•çˆ¬è™«

è‹¥å­˜åœ¨ `deploy/quick_deploy.sh`ï¼Œå¯ä¸€é”®å®Œæˆï¼šå¯ç”¨ APIã€åˆ›å»º BigQueryã€æ›´æ–° configã€éƒ¨ç½² Cloud Functionsã€‚

```bash
cd /path/to/news-google
./deploy/quick_deploy.sh
```

**é¢„è®¡æ—¶é—´**ï¼š5-10 åˆ†é’Ÿ

---

### æ–¹æ³• 3ï¼šåˆ†æ­¥éƒ¨ç½²ï¼ˆæ‰‹åŠ¨æ§åˆ¶ï¼‰

#### æ­¥éª¤ 1ï¼šå¯ç”¨ API
```bash
gcloud config set project $GCP_PROJECT_ID

gcloud services enable \
  cloudfunctions.googleapis.com \
  cloudscheduler.googleapis.com \
  bigquery.googleapis.com \
  cloudbuild.googleapis.com \
  run.googleapis.com
```

#### æ­¥éª¤ 2ï¼šåˆ›å»º BigQuery è¡¨
```bash
bq mk --dataset --location=US "$GCP_PROJECT_ID:news_project"
bq query --use_legacy_sql=false < deploy/create_bigquery_table.sql
```

**éªŒè¯**ï¼š
```bash
bq show news_project.news_articles
```

> è¡¨ä¸ºæŒ‰ `pub_date` åˆ†åŒºï¼ŒæŸ¥è¯¢æ—¶å¿…é¡»å¸¦ `DATE(pub_date)` æ¡ä»¶ã€‚

#### æ­¥éª¤ 3ï¼šæ›´æ–°é…ç½®æ–‡ä»¶
```bash
sed -i.bak "s/your-project-id/$GCP_PROJECT_ID/g" config.yaml
rm -f config.yaml.bak
```

#### æ­¥éª¤ 4ï¼šéƒ¨ç½²ç®€å•çˆ¬è™«ï¼ˆCloud Functionsï¼‰
```bash
sh deploy/deploy.sh
```

#### æ­¥éª¤ 5ï¼ˆå¯é€‰ï¼‰ï¼šéƒ¨ç½²æ— å¤´æµè§ˆå™¨çˆ¬è™«ï¼ˆCloud Runï¼‰
```bash
sh deploy/deploy_cloudrun_browser.sh
```
ä¼šæ„å»ºå¹¶éƒ¨ç½²åˆ° Cloud Runï¼Œå¹¶é…ç½® Cloud Scheduler æ¯ 30 åˆ†é’Ÿè§¦å‘ã€‚ä½¿ç”¨ `Dockerfile.firefox`ï¼ˆä»… Firefoxï¼‰ã€‚

---

## âœ… æµ‹è¯•éªŒè¯

### 1. è·å–å‡½æ•° URL
```bash
FUNCTION_URL=$(gcloud functions describe crawl-news \
  --region=$GCP_REGION \
  --gen2 \
  --format="value(serviceConfig.uri)")

echo "å‡½æ•° URL: $FUNCTION_URL"
```

### 2. æµ‹è¯•å•ä¸ªçˆ¬è™«
```bash
curl -X POST \
  -H "Content-Type: application/json" \
  -d '{"sources": "techcrunch"}' \
  $FUNCTION_URL
```

**æœŸæœ›è¾“å‡º**ï¼š
```json
{
  "success": true,
  "total_new_articles": 3,
  "total_skipped": 0,
  "total_errors": 0,
  "results": {
    "techcrunch": {
      "new_articles": 3,
      "skipped": 0,
      "errors": 0
    }
  },
  "errors": []
}
```

### 3. æµ‹è¯•å¤šä¸ªçˆ¬è™«
```bash
curl -X POST \
  -H "Content-Type: application/json" \
  -d '{"sources": "techcrunch,apnews,coinlive"}' \
  $FUNCTION_URL
```

### 4. éªŒè¯æ•°æ®å†™å…¥ BigQuery
```bash
# æŸ¥è¯¢ä»Šå¤©çˆ¬å–çš„æ–‡ç« ï¼ˆå¿…é¡»å¸¦ pub_date åˆ†åŒºæ¡ä»¶ï¼‰
bq query --use_legacy_sql=false \
  "SELECT source, COUNT(*) as count
   FROM \`$GCP_PROJECT_ID.news_project.news_articles\`
   WHERE DATE(pub_date) >= CURRENT_DATE()
   GROUP BY source"
```

**æœŸæœ›è¾“å‡º**ï¼š
```
+------------+-------+
|   source   | count |
+------------+-------+
| techcrunch |     3 |
| apnews     |     3 |
| coinlive   |     4 |
+------------+-------+
```

### 5. æŸ¥çœ‹å‡½æ•°æ—¥å¿—
```bash
gcloud logging read \
  "resource.type=cloud_function AND resource.labels.function_name=crawl-news" \
  --limit=20 \
  --format=json
```

### 6. æµ‹è¯•æ— å¤´æµè§ˆå™¨çˆ¬è™«ï¼ˆè‹¥å·²éƒ¨ç½² Cloud Runï¼‰
```bash
# ä» deploy_cloudrun_browser.sh è¾“å‡ºæˆ–æ§åˆ¶å°è·å–æœåŠ¡ URLï¼Œä¾‹å¦‚ï¼š
curl -X POST -H "Content-Type: application/json" \
  -d '{"sources": "stcn", "test": true}' \
  https://crawl-news-browser-xxxxx-uc.a.run.app
```

---

## ğŸ”” é…ç½®å®šæ—¶ä»»åŠ¡

éƒ¨ç½²æˆåŠŸåï¼Œé…ç½® Cloud Scheduler æ¯ 10 åˆ†é’Ÿè‡ªåŠ¨è§¦å‘ï¼š

```bash
./deploy/setup_scheduler.sh
```

**éªŒè¯å®šæ—¶ä»»åŠ¡**ï¼š
```bash
# æŸ¥çœ‹ä»»åŠ¡è¯¦æƒ…
gcloud scheduler jobs describe news-crawler-job \
  --location=$GCP_REGION

# æ‰‹åŠ¨è§¦å‘æµ‹è¯•
gcloud scheduler jobs run news-crawler-job \
  --location=$GCP_REGION
```

---

## ğŸ“Š ç›‘æ§ä¸ç®¡ç†

### æŸ¥çœ‹çˆ¬å–ç»Ÿè®¡
```bash
# å„æ–°é—»æºç»Ÿè®¡ï¼ˆéœ€å¸¦ pub_date åˆ†åŒºæ¡ä»¶ï¼‰
bq query --use_legacy_sql=false \
  "SELECT source, COUNT(*) as cnt
   FROM \`$GCP_PROJECT_ID.news_project.news_articles\`
   WHERE DATE(pub_date) >= DATE_SUB(CURRENT_DATE(), INTERVAL 7 DAY)
   GROUP BY source ORDER BY cnt DESC"

# æœ€è¿‘çˆ¬å–çš„æ–‡ç« 
bq query --use_legacy_sql=false \
  "SELECT title, source, pub_date, link
   FROM \`$GCP_PROJECT_ID.news_project.news_articles\`
   WHERE DATE(pub_date) >= DATE_SUB(CURRENT_DATE(), INTERVAL 7 DAY)
   ORDER BY crawled_at DESC
   LIMIT 10"
```

### æŸ¥çœ‹å‡½æ•°æ‰§è¡Œæƒ…å†µ
```bash
# æŸ¥çœ‹æœ€è¿‘çš„æ‰§è¡Œ
gcloud functions describe crawl-news \
  --region=$GCP_REGION \
  --gen2

# æŸ¥çœ‹æŒ‡æ ‡
gcloud monitoring time-series list \
  --filter='metric.type="cloudfunctions.googleapis.com/function/execution_count"'
```

---

## ğŸ› ï¸ å¸¸è§é—®é¢˜

### é—®é¢˜ 1ï¼šéƒ¨ç½²å¤±è´¥ - API æœªå¯ç”¨
```bash
# é”™è¯¯ä¿¡æ¯ï¼šAPI [xxx] not enabled
# è§£å†³æ–¹æ¡ˆï¼šæ‰‹åŠ¨å¯ç”¨ API
gcloud services enable cloudfunctions.googleapis.com
```

### é—®é¢˜ 2ï¼šBigQuery è¡¨å·²å­˜åœ¨
```bash
# é”™è¯¯ä¿¡æ¯ï¼šAlready Exists: Table
# è§£å†³æ–¹æ¡ˆï¼šåˆ é™¤é‡å»ºï¼ˆä¼šä¸¢å¤±æ•°æ®ï¼‰
bq rm -f -t news_project.news_articles
bq query --use_legacy_sql=false < deploy/create_bigquery_table.sql
```

### é—®é¢˜ 3ï¼šå‡½æ•°è°ƒç”¨å¤±è´¥
```bash
# æŸ¥çœ‹è¯¦ç»†æ—¥å¿—
gcloud logging read \
  "resource.type=cloud_function" \
  --limit=50 \
  --format=json | jq '.[] | select(.severity=="ERROR")'
```

### é—®é¢˜ 4ï¼šæƒé™ä¸è¶³
```bash
# ç¡®ä¿æœåŠ¡è´¦å·æœ‰ BigQuery æƒé™
gcloud projects add-iam-policy-binding $GCP_PROJECT_ID \
  --member="serviceAccount:$GCP_PROJECT_ID@appspot.gserviceaccount.com" \
  --role="roles/bigquery.dataEditor"
```

---

## ğŸ”„ æ›´æ–°ä¸ç»´æŠ¤

### æ›´æ–°çˆ¬è™«ä»£ç 
```bash
# ç®€å•çˆ¬è™«
make deploy
# æˆ– sh deploy/deploy.sh

# æ— å¤´æµè§ˆå™¨çˆ¬è™«
make deploy-browser
# æˆ– sh deploy/deploy_cloudrun_browser.sh
```

### æ·»åŠ æ–°çˆ¬è™«
- **ç®€å•çˆ¬è™«**ï¼šåœ¨ `scrapers/simple/` æ–°å»ºæ¨¡å—ï¼Œç»§æ‰¿ `BaseScraper`ï¼Œåœ¨ `main.py` çš„ `SCRAPER_REGISTRY` ä¸­æ³¨å†Œï¼Œç„¶å `make deploy`ã€‚
- **æ— å¤´æµè§ˆå™¨çˆ¬è™«**ï¼šåœ¨ `scrapers/browser/` æ–°å»ºæ¨¡å—ï¼Œç»§æ‰¿ `BaseBrowserScraper` å¹¶å®ç° `_run_impl()`ï¼Œåœ¨ `scrapers/browser/__init__.py` çš„ `SCRAPER_REGISTRY_BROWSER` ä¸­æ³¨å†Œï¼Œç„¶å `make deploy-browser`ã€‚

### æš‚åœ/æ¢å¤å®šæ—¶ä»»åŠ¡
```bash
# æš‚åœ
gcloud scheduler jobs pause news-crawler-job --location=$GCP_REGION

# æ¢å¤
gcloud scheduler jobs resume news-crawler-job --location=$GCP_REGION
```

### åˆ é™¤æ‰€æœ‰èµ„æº
```bash
# ç®€å•çˆ¬è™«
gcloud functions delete crawl-news --region=$GCP_REGION --gen2
gcloud scheduler jobs delete news-crawler-job --location=$GCP_REGION 2>/dev/null || true

# æ— å¤´æµè§ˆå™¨çˆ¬è™«ï¼ˆè‹¥å·²éƒ¨ç½²ï¼‰
gcloud run services delete crawl-news-browser --region=$GCP_REGION
gcloud scheduler jobs delete news-crawler-browser-job --location=$GCP_REGION 2>/dev/null || true

# BigQuery æ•°æ®é›†ï¼ˆåŒ…å«æ‰€æœ‰è¡¨ï¼‰
bq rm -r -f $GCP_PROJECT_ID:news_project
```

---

## ğŸ’° æˆæœ¬ç›‘æ§

### æŸ¥çœ‹å½“å‰æœˆè´¹ç”¨
```bash
gcloud billing accounts list

# åœ¨ GCP Console æŸ¥çœ‹è¯¦ç»†è´¦å•
# https://console.cloud.google.com/billing
```

### é¢„è®¡æˆæœ¬
- Cloud Functionsï¼ˆç®€å•çˆ¬è™«ï¼‰: $3-5/æœˆ
- Cloud Runï¼ˆæ— å¤´æµè§ˆå™¨ï¼ŒæŒ‰è¯·æ±‚ï¼‰: è§†è°ƒç”¨é¢‘ç‡è€Œå®š
- BigQuery: $0.5-2/æœˆ
- **æ€»è®¡**: çº¦ **$4-10/æœˆ**ï¼ˆè§†æ˜¯å¦å¯ç”¨æµè§ˆå™¨çˆ¬è™«åŠè°ƒåº¦é¢‘ç‡ï¼‰

---

## ğŸ“š ä¸‹ä¸€æ­¥

éƒ¨ç½²å®Œæˆåï¼Œæ‚¨å¯ä»¥ï¼š

1. âœ… è¿ç§»æ›´å¤šæ–°é—»æºï¼ˆå‚è€ƒç°æœ‰ä»£ç ï¼‰
2. âœ… æ·»åŠ ç›‘æ§å‘Šè­¦
3. âœ… é›†æˆ BI å·¥å…·åˆ†ææ•°æ®
4. âœ… å¯¼å‡ºæ•°æ®åˆ°å…¶ä»–ç³»ç»Ÿ

---

## ğŸ†˜ è·å–å¸®åŠ©

- æŸ¥çœ‹ README.md
- GitHub Issuesï¼ˆå¦‚æœæœ‰ï¼‰

**ç¥éƒ¨ç½²é¡ºåˆ©ï¼** ğŸ‰
